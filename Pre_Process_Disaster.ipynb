{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(path):\n",
    "    disaster_folders=os.listdir(path)\n",
    "    \n",
    "    data=[]\n",
    "    uniq_labels={}\n",
    "    \n",
    "    for disaster_folder in disaster_folders:\n",
    "        folder_path=os.path.join(path,disaster_folder)\n",
    "        #print('folderPath',folder_path)\n",
    "        labeled_csv_file=disaster_folder+'-tweets_labeled.csv'\n",
    "        #print('labeled_csv_file',labeled_csv_file)\n",
    "        csv_file_path=os.path.join(folder_path,labeled_csv_file)\n",
    "        #print('csv_file_path',csv_file_path)\n",
    "        with open(csv_file_path, newline='',encoding=\"utf8\") as f:\n",
    "            reader = csv.reader(f, delimiter=',')\n",
    "            next(reader)\n",
    "            for line in reader:\n",
    "                text=line[1]\n",
    "                label=line[3]\n",
    "                if label=='Not labeled':\n",
    "                    continue\n",
    "                text=re.sub(r'http\\S+', 'URL', text)\n",
    "                if label not in uniq_labels:\n",
    "                    uniq_labels[label]=label\n",
    "                data.append({'text':text,'label':label})\n",
    "    return data,uniq_labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_data,wf_labels=read_files('./CrisisLexT26_Flood_Wildfire/wildfires')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_data,flood_labels=read_files('./CrisisLexT26_Flood_Wildfire/floods')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_data,mm_labels=read_files('./CrisisLexT26_Flood_Wildfire/manmade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2827, 1902, 3759)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flood_data),len(wf_data),len(mm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_train ,flood_test = train_test_split(flood_data,test_size=0.25,random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_train,flood_dev=train_test_split(flood_train,test_size=0.3,random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_train,mm_test=train_test_split(mm_data,test_size=0.25,random_state=11)\n",
    "mm_train,mm_dev=train_test_split(mm_train,test_size=0.3,random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_file(listt,file_name):\n",
    "    with open(file_name, 'w',encoding=\"utf-8\") as f:\n",
    "        for item in listt:\n",
    "            data=item['text']+'\\t'+item['label']\n",
    "            f.write(\"%s\\n\" % data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_file(flood_train,'./CrisisLexT26_Flood_Wildfire/floods_processed/train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_file(flood_dev,'./CrisisLexT26_Flood_Wildfire/floods_processed/dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_file(flood_test,'./CrisisLexT26_Flood_Wildfire/floods_processed/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_train ,wf_test = train_test_split(wf_data,test_size=0.25,random_state=11)\n",
    "wf_train ,wf_dev = train_test_split(wf_train,test_size=0.25,random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_file(wf_train,'./CrisisLexT26_Flood_Wildfire/wildfires_processed/train.txt')\n",
    "convert_to_file(wf_test,'./CrisisLexT26_Flood_Wildfire/wildfires_processed/test.txt')\n",
    "convert_to_file(wf_dev,'./CrisisLexT26_Flood_Wildfire/wildfires_processed/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_file(mm_train,'./CrisisLexT26_Flood_Wildfire/manmade_processed/train.txt')\n",
    "convert_to_file(mm_test,'./CrisisLexT26_Flood_Wildfire/manmade_processed/test.txt')\n",
    "convert_to_file(mm_dev,'./CrisisLexT26_Flood_Wildfire/manmade_processed/dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
